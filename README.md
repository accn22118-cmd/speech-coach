# Speech Coach API

Сервис для анализа качества публичной речи по загружаемым видеофайлам. Извлекает аудиодорожку, выполняет локальное распознавание речи с помощью [Whisper](https://github.com/openai/whisper) через [faster-whisper](https://github.com/SYSTRAN/faster-whisper), анализирует ключевые метрики и предоставляет структурированные рекомендации с возможностью расширенного AI-анализа через [GigaChat API](https://developers.sber.ru/portal/products/gigachat).

## Быстрый старт

```bash
# Клонирование репозитория
git clone https://github.com/xXxDanya2007xXx/speech-coach.git
cd speech-coach

# Создание виртуального окружения
python -m venv .venv

# Активация окружения
# Linux/macOS:
source .venv/bin/activate
# Windows (PowerShell):
.\\.venv\\Scripts\\Activate.ps1
# Windows (CMD):
.venv\\Scripts\\activate

# Установка зависимостей
pip install -r requirements.txt

# Настройка конфигурации
cp .env.example .env

# Запуск сервера разработки
uvicorn app.main:app --reload
```

После запуска API будет доступен по адресу `http://127.0.0.1:8000`. Интерактивная документация (Swagger UI) доступна по пути `/docs`.

## Использование API

Основной эндпоинт для анализа видеофайла:

```bash
curl -X POST "http://127.0.0.1:8000/api/v1/analyze" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@path/to/your/video.mp4"
```

**Поддерживаемые форматы видео:** MP4, MOV, AVI, MKV, WEBM, FLV, WMV, M4V  
**Максимальный размер файла:** 100 MB

## Конфигурация

Ключевые настройки определяются в файле `.env`:

```env
# Обязательные настройки
FFMPEG_PATH=ffmpeg
WHISPER_MODEL=small
WHISPER_DEVICE=cpu
MAX_FILE_SIZE_MB=100

# Опциональные настройки для GigaChat API
GIGACHAT_ENABLED=false
# GIGACHAT_API_KEY=your_authorization_key_here
```

Полный список доступных параметров представлен в файле [.env.example](.env.example).

## Анализируемые метрики

- **Темп речи** – количество слов в минуту, рассчитанное по чистому времени говорения
- **Слова-паразиты** – частота использования заполнителей пауз на русском и английском языках
- **Паузы** – количество, средняя и максимальная длительность, распределение
- **Структура фраз** – средняя длина фразы, классификация по длине, вариативность ритма
- **Коэффициент говорения** – доля времени, в течение которого спикер говорит

## Архитектура системы

Основные компоненты сервиса:

1. **Pipeline** – координирует процесс обработки от загрузки видео до формирования результата
2. **Audio Extractor** – извлекает аудиодорожку с помощью FFmpeg
3. **Transcriber** – выполняет распознавание речи с использованием модели Whisper
4. **Analyzer** – рассчитывает метрики качества речи и генерирует рекомендации
5. **GigaChat Client** – обеспечивает интеграцию с GigaChat API для расширенного AI-анализа (опционально)

## Устранение неполадок

1. **Ошибка "FFmpeg not found"** – убедитесь, что FFmpeg установлен и доступен в PATH
2. **Длительная загрузка при первом запуске** – сервис загружает модель Whisper при первом использовании
3. **Ошибка памяти при анализе больших файлов** – уменьшите значение `MAX_FILE_SIZE_MB` или используйте модель меньшего размера (`WHISPER_MODEL=tiny` или `WHISPER_MODEL=base`)

## Структура проекта

```
speech-coach/
├── app/                # Основной код приложения
│   ├── api/routes/     # Маршруты FastAPI
│   ├── core/           # Конфигурация и утилиты
│   ├── models/         # Pydantic модели данных
│   ├── services/       # Бизнес-логика и сервисы
│   └── main.py         # Точка входа
├── .env.example        # Пример файла конфигурации
├── requirements.txt    # Зависимости Python
└── README.md           # Документация
```

## Лицензия

Проект распространяется под лицензией MIT. Полный текст лицензии доступен в файле [LICENSE](LICENSE).
